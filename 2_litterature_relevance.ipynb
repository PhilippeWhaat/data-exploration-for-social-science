{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openpyxl import Workbook\n",
    "\n",
    "# Répertoire contenant les fichiers PDF\n",
    "pdf_directory = \"src/google_scholar\"\n",
    "\n",
    "# Créer un nouveau classeur Excel\n",
    "wb = Workbook()\n",
    "ws = wb.active\n",
    "\n",
    "# Écrire le nom des fichiers PDF dans la première colonne\n",
    "for filename in os.listdir(pdf_directory):\n",
    "    if filename.endswith(\".pdf\"):\n",
    "        ws.append([filename])\n",
    "\n",
    "# Enregistrer le fichier Excel\n",
    "excel_filename = \"liste_fichiers.xlsx\"\n",
    "wb.save(excel_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "import os\n",
    "import pandas as pd\n",
    "import openai\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.organization = os.environ['OPENAI_ORG_KEY']\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "# Start from begginning\n",
    "df = pd.read_excel(\"liste_fichiers_completed.xlsx\")\n",
    "\n",
    "# Start from last processed\n",
    "#df = pd.read_csv(\"eval.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_tokens_from_string(string: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def content_eval(part, title, content):\n",
    "    # 'part' can be 'abstract', 'results' or 'conclusion'\n",
    "    \n",
    "        \n",
    "#     role = f\"\"\"Given the overarching research question - 'What is the current state of research on the challenges, limitations, and potential impact of using causal AI techniques for automatic legal language processing and its application in legal decision-making compared to non-causal AI models relying on correlations?' - and the more specific sub-questions, I evaluate the relevance of the following article based on its {part} and title. I consider if the article addresses the following points:\n",
    "\n",
    "#     1. The challenges in interpreting and understanding the meaning of legal language, and how these impact the ability of AI models to analyze and make decisions based on legal texts.\n",
    "#     2. The relationship between causal inference algorithms and the process of legal language understanding.\n",
    "#     3. Methods to overcome the lack of empirical context in the causal analysis of legal texts, and suggestions for collecting data on a sufficient set of variables to block all the backdoor paths between the intervention and the outcome.\n",
    "#     4. The challenges and limitations in conducting automatic analysis of legal corpora and whether it proposes a theoretical framework to evaluate the causal links in the models produced.\n",
    "#     5. The potential impact of using causal AI techniques in the field of automatic legal language processing and its application in legal decision-making compared to traditional AI models relying on correlations.\n",
    "\n",
    "# I provide a brief reasoning for my evaluation.\"\"\"\n",
    "\n",
    "    role = \"\"\"\n",
    "In light of our primary research query - 'What is the prevailing status of studies concerning the difficulties, constraints, and potential effects of applying causal AI methods to automatic legal language processing and their role in legal decision-making, in comparison to non-causal AI models that rely on correlations?' - and the associated, more detailed, sub-questions, I express my feelings about the relevance of the selected article based on its {part} and title. \n",
    "\n",
    "Rather than simply stating the relevance as \"positive\" or \"negative\", I describe how the article makes me feel in a more human way, as they would on social media like Twitter or Facebook. I express feelings of excitement, disappointment, surprise, interest, confusion, optimism, skepticism, and other emotions that arise while considering the relevance of the article. I try to weave these emotions throughout my response, rather than just stating them at the beginning.\n",
    "\n",
    "The evaluation hinges on whether the article addresses these specific aspects:\n",
    "     1. The challenges in interpreting and understanding the meaning of legal language, and how these impact the ability of AI models to analyze and make decisions based on legal texts.\n",
    "     2. The relationship between causal inference algorithms and the process of legal language understanding.\n",
    "     3. Methods to overcome the lack of empirical context in the causal analysis of legal texts, and suggestions for collecting data on a sufficient set of variables to block all the backdoor paths between the intervention and the outcome.\n",
    "     4. The challenges and limitations in conducting automatic analysis of legal corpora and whether it proposes a theoretical framework to evaluate the causal links in the models produced.\n",
    "     5. The potential impact of using causal AI techniques in the field of automatic legal language processing and its application in legal decision-making compared to traditional AI models relying on correlations.\n",
    "\n",
    "Both the polarity (positive/negative) and the intensity (strength) of emotion will be expressed in my language, with punctuation such as exclamation points to increase the intensity of sentiment, capitalization of words, emotional degree modifiers and and shifters.\n",
    "\"\"\" \n",
    "    prompt = f\"Title: \" + title + f\"\"\"\n",
    "\n",
    "{part.capitalize()}: \"\"\" + content \n",
    "    \n",
    "    answer = f\"Based on the title and {part}, \"\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            completions = openai.ChatCompletion.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                messages=[\n",
    "                { \"role\": \"assistant\", \"content\": role\n",
    "                },\n",
    "                { \"role\": \"user\", \"content\": prompt},\n",
    "                { \"role\": \"assistant\", \"content\": answer}\n",
    "                ],\n",
    "                #max_tokens=num_tokens_from_string(role + \" \" + prompt + \" \" + answer) + 200,\n",
    "                max_tokens = 200,\n",
    "            )\n",
    "            return completions['choices'][0]['message']['content']\n",
    "        except openai.error.RateLimitError:  # handle the specific RateLimitError\n",
    "            print('API overload, waiting for 10 seconds...')\n",
    "            time.sleep(10)\n",
    "        except Exception as e:\n",
    "            # Handle any other exceptions that might occur\n",
    "            print(\"Error:\", str(e))\n",
    "            time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "parts = ['abstract']\n",
    "\n",
    "# Creating new columns with empty lists\n",
    "for part in parts:\n",
    "    df['feedback_' + part] = [[] for _ in range(len(df))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API overload, waiting for 10 seconds...\n",
      "API overload, waiting for 10 seconds...\n",
      "API overload, waiting for 10 seconds...\n",
      "API overload, waiting for 10 seconds...\n",
      "API overload, waiting for 10 seconds...\n",
      "API overload, waiting for 10 seconds...\n",
      "API overload, waiting for 10 seconds...\n",
      "API overload, waiting for 10 seconds...\n",
      "API overload, waiting for 10 seconds...\n",
      "API overload, waiting for 10 seconds...\n",
      "API overload, waiting for 10 seconds...\n",
      "API overload, waiting for 10 seconds...\n",
      "API overload, waiting for 10 seconds...\n",
      "API overload, waiting for 10 seconds...\n",
      "API overload, waiting for 10 seconds...\n",
      "API overload, waiting for 10 seconds...\n",
      "API overload, waiting for 10 seconds...\n",
      "API overload, waiting for 10 seconds...\n",
      "API overload, waiting for 10 seconds...\n",
      "API overload, waiting for 10 seconds...\n",
      "API overload, waiting for 10 seconds...\n",
      "API overload, waiting for 10 seconds...\n",
      "API overload, waiting for 10 seconds...\n",
      "API overload, waiting for 10 seconds...\n"
     ]
    }
   ],
   "source": [
    "for part in parts:\n",
    "    # Apply function if rows is not empty string nor NaN\n",
    "    for idx, row in df[df[part].notna() & (df[part] != '')].iterrows():\n",
    "        title = row['name']\n",
    "        content = row[part]\n",
    "        \n",
    "        feedback_col_name = 'feedback_' + part\n",
    "        # start from the next index if the list is not empty\n",
    "        start_index = len(df.at[idx, feedback_col_name]) if df.at[idx, feedback_col_name] else 0\n",
    "\n",
    "        for i in range(start_index, 40):\n",
    "            feedback = content_eval(part, title, content)\n",
    "            # append feedback to the list\n",
    "            df.at[idx, feedback_col_name] = df.at[idx, feedback_col_name] + [feedback] if df.at[idx, feedback_col_name] else [feedback]\n",
    "        \n",
    "            # Save progress after each successful iteration\n",
    "            df.to_csv('eval_sentiment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5101880"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = 0\n",
    "for part in parts:\n",
    "    # Appliquer la fonction à chaque ligne non vide et non NaN\n",
    "    for idx, row in df[df[part].notna() & (df[part] != '')].iterrows():\n",
    "        title = row['name']\n",
    "        content = row[part]\n",
    "        \n",
    "        data = []\n",
    "        tokens_p = num_tokens_from_string(part + ' ' + title + ' ' + content) + 275 + 200\n",
    "        for i in range(0,49):\n",
    "            tokens+= tokens_p\n",
    "\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.20376"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.002*tokens/1000\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
